{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_refresh.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRhW3Xqtz60j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "39542ec2-f5b9-40fb-bc91-5fde4c7abe3b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 06:32:41.555330 139943368959872 deprecation.py:323] From <ipython-input-1-1d8ffff3e42a>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0725 06:32:41.556877 139943368959872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0725 06:32:41.557821 139943368959872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0725 06:32:41.797849 139943368959872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0725 06:32:41.841245 139943368959872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrOgvh211MgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4c5764e-3f3c-4b9f-b8e5-44f251a5cfab"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.unique(mnist.train._labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWq--42n6-Nw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c07fe6e6-570e-4242-f3f8-c5b7e3bb229a"
      },
      "source": [
        "class CNN:\n",
        "  def __init__(self, learning_rate):\n",
        "    self.X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "    self.Y = tf.placeholder(tf.int32, [None])\n",
        "    conv1 = tf.layers.conv2d(self.X, \n",
        "                             filters = 32,\n",
        "                             kernel_size = 5,\n",
        "                             strides=(1, 1),\n",
        "                             padding='same',\n",
        "                             activation = tf.nn.relu)\n",
        "    \n",
        "    pooling1 = tf.layers.max_pooling2d(conv1, pool_size = 2,\n",
        "                                       strides = (2, 2),\n",
        "                                       padding='valid')\n",
        "    conv2 = tf.layers.conv2d(pooling1, \n",
        "                             filters = 64,\n",
        "                             kernel_size = 5,\n",
        "                             strides=(1, 1),\n",
        "                             padding='same',\n",
        "                             activation = tf.nn.relu)\n",
        "    pooling2 = tf.layers.max_pooling2d(conv2, pool_size = 2,\n",
        "                                       strides = (2, 2),\n",
        "                                       padding='valid')\n",
        "    \n",
        "    conv3 = tf.layers.conv2d(pooling2, \n",
        "                             filters = 64,\n",
        "                             kernel_size = 5,\n",
        "                             strides=(1, 1),\n",
        "                             padding='same',\n",
        "                             activation = tf.nn.relu)\n",
        "    \n",
        "    pooling3 = tf.layers.max_pooling2d(conv3, pool_size = 2,\n",
        "                                       strides = (2, 2),\n",
        "                                       padding='valid')\n",
        "    \n",
        "    pooled = tf.layers.flatten(pooling3)\n",
        "    self.logits = tf.layers.dense(pooled, 10)\n",
        "    self.cost = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "    labels = self.Y, logits = self.logits)\n",
        "    self.cost = tf.reduce_mean(self.cost)\n",
        "    self.optimizer = tf.train.AdamOptimizer(learning_rate) \\\n",
        "    .minimize(self.cost)\n",
        "    correct_pred = tf.equal(\n",
        "            tf.argmax(self.logits, 1, output_type = tf.int32), self.Y\n",
        "        )\n",
        "    self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    \n",
        "learning_rate = 1e-4\n",
        "batch_size = 128\n",
        "epoch = 10\n",
        "\n",
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()\n",
        "model = CNN(learning_rate)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for e in range(epoch):\n",
        "  pbar = tqdm(\n",
        "        range(0, len(mnist.train._labels), batch_size), desc = 'train loop'\n",
        "    )\n",
        "  train_loss, train_acc, test_loss, test_acc = [], [], [], []\n",
        "  for i in pbar:\n",
        "    index = min(i + batch_size, len(mnist.train._labels))\n",
        "    batch_x = mnist.train._images[i: index]\n",
        "    batch_x = np.reshape(batch_x, (-1, 28, 28, 1))\n",
        "    batch_y = mnist.train._labels[i: index]\n",
        "    _, cost, accuracy = sess.run([model.optimizer, model.cost, model.accuracy],\n",
        "                      feed_dict = {model.X: batch_x,\n",
        "                                  model.Y: batch_y})\n",
        "    train_loss.append(cost)\n",
        "    train_acc.append(accuracy)\n",
        "    pbar.set_postfix(cost = cost, accuracy = accuracy)\n",
        "\n",
        "  pbar = tqdm(\n",
        "        range(0, len(mnist.test._labels), batch_size), desc = 'test loop'\n",
        "    )  \n",
        "  for i in pbar:\n",
        "    index = min(i + batch_size, len(mnist.test._labels))\n",
        "    batch_x = mnist.test._images[i: index]\n",
        "    batch_x = np.reshape(batch_x, (-1, 28, 28, 1))\n",
        "    batch_y = mnist.test._labels[i: index]\n",
        "    cost, accuracy = sess.run([model.cost, model.accuracy],\n",
        "                      feed_dict = {model.X: batch_x,\n",
        "                                  model.Y: batch_y})\n",
        "    test_loss.append(cost)\n",
        "    test_acc.append(accuracy)\n",
        "    pbar.set_postfix(cost = cost, accuracy = accuracy)\n",
        "  \n",
        "  \n",
        "  print('\\nepoch: %d, avg train loss: %f, avg train accuracy: %f'%(e + 1,\n",
        "                                                             np.mean(train_loss),\n",
        "                                                             np.mean(train_acc)))\n",
        "  print('epoch: %d, avg test loss: %f, avg test accuracy: %f'%(e + 1,\n",
        "                                                             np.mean(test_loss),\n",
        "                                                             np.mean(test_acc)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 07:00:01.374921 139943368959872 deprecation.py:323] From <ipython-input-3-00f2d0ab0ba1>:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "W0725 07:00:01.381520 139943368959872 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0725 07:00:01.612822 139943368959872 deprecation.py:323] From <ipython-input-3-00f2d0ab0ba1>:14: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "W0725 07:00:01.781600 139943368959872 deprecation.py:323] From <ipython-input-3-00f2d0ab0ba1>:36: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0725 07:00:02.148298 139943368959872 deprecation.py:323] From <ipython-input-3-00f2d0ab0ba1>:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "train loop: 100%|██████████| 430/430 [00:07<00:00, 60.78it/s, accuracy=0.955, cost=0.329] \n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 185.87it/s, accuracy=1, cost=0.0944]\n",
            "train loop:   3%|▎         | 11/430 [00:00<00:04, 101.33it/s, accuracy=0.938, cost=0.245]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 1, avg train loss: 0.667287, avg train accuracy: 0.840410\n",
            "epoch: 1, avg test loss: 0.201706, avg test accuracy: 0.940071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:03<00:00, 108.47it/s, accuracy=0.989, cost=0.287]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 204.53it/s, accuracy=1, cost=0.0167]\n",
            "train loop:   3%|▎         | 12/430 [00:00<00:03, 119.90it/s, accuracy=0.953, cost=0.131]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 2, avg train loss: 0.178951, avg train accuracy: 0.947230\n",
            "epoch: 2, avg test loss: 0.128190, avg test accuracy: 0.960245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:03<00:00, 109.19it/s, accuracy=0.989, cost=0.287]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 202.75it/s, accuracy=1, cost=0.00502]\n",
            "train loop:   3%|▎         | 11/430 [00:00<00:03, 105.63it/s, accuracy=0.961, cost=0.112]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 3, avg train loss: 0.123448, avg train accuracy: 0.963146\n",
            "epoch: 3, avg test loss: 0.098550, avg test accuracy: 0.967860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:03<00:00, 108.46it/s, accuracy=0.989, cost=0.288]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 212.93it/s, accuracy=1, cost=0.00218]\n",
            "train loop:   3%|▎         | 11/430 [00:00<00:03, 106.80it/s, accuracy=0.953, cost=0.0962]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 4, avg train loss: 0.096971, avg train accuracy: 0.970686\n",
            "epoch: 4, avg test loss: 0.082137, avg test accuracy: 0.973398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:04<00:00, 107.08it/s, accuracy=0.989, cost=0.285]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 197.27it/s, accuracy=1, cost=0.00117]\n",
            "train loop:   3%|▎         | 11/430 [00:00<00:04, 103.51it/s, accuracy=0.969, cost=0.0777]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 5, avg train loss: 0.080839, avg train accuracy: 0.975918\n",
            "epoch: 5, avg test loss: 0.072029, avg test accuracy: 0.976464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:04<00:00, 105.92it/s, accuracy=0.989, cost=0.281]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 200.29it/s, accuracy=1, cost=0.000725]\n",
            "train loop:   3%|▎         | 11/430 [00:00<00:03, 104.96it/s, accuracy=0.969, cost=0.0684]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 6, avg train loss: 0.069579, avg train accuracy: 0.978807\n",
            "epoch: 6, avg test loss: 0.064612, avg test accuracy: 0.978540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:03<00:00, 107.70it/s, accuracy=0.989, cost=0.278]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 191.26it/s, accuracy=1, cost=0.000499]\n",
            "train loop:   3%|▎         | 11/430 [00:00<00:03, 109.23it/s, accuracy=0.977, cost=0.0615]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 7, avg train loss: 0.061128, avg train accuracy: 0.981423\n",
            "epoch: 7, avg test loss: 0.058542, avg test accuracy: 0.980914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:04<00:00, 105.66it/s, accuracy=0.989, cost=0.274]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 212.38it/s, accuracy=1, cost=0.000333]\n",
            "train loop:   3%|▎         | 12/430 [00:00<00:03, 119.33it/s, accuracy=0.977, cost=0.0473]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 8, avg train loss: 0.054488, avg train accuracy: 0.983386\n",
            "epoch: 8, avg test loss: 0.054286, avg test accuracy: 0.981903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:03<00:00, 108.85it/s, accuracy=0.989, cost=0.267]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 207.25it/s, accuracy=1, cost=0.000244]\n",
            "train loop:   3%|▎         | 11/430 [00:00<00:03, 109.70it/s, accuracy=0.984, cost=0.044] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 9, avg train loss: 0.049025, avg train accuracy: 0.984912\n",
            "epoch: 9, avg test loss: 0.050973, avg test accuracy: 0.982595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 430/430 [00:04<00:00, 106.98it/s, accuracy=0.989, cost=0.26]\n",
            "test loop: 100%|██████████| 79/79 [00:00<00:00, 196.07it/s, accuracy=1, cost=0.000163]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch: 10, avg train loss: 0.044467, avg train accuracy: 0.986511\n",
            "epoch: 10, avg test loss: 0.048420, avg test accuracy: 0.982595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1HNFIL082-7",
        "colab_type": "text"
      },
      "source": [
        "## Can try refer to tensorflow finished code\n",
        "https://github.com/tensorflow/models/tree/master/research/slim # image recognition zoo\n",
        "    \n",
        "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md # object detection zoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FDBBLBo7hSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}